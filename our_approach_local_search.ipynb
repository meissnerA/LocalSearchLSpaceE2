{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Keep it Simple: Local Search-based Latent Space Editing\n",
    "Meißner, A.; Fröhlich, A. and Geierhos, M. (2022). Keep It Simple: Local Search-based Latent Space Editing. In Proceedings of the 14th International Joint Conference on Computational Intelligence - NCTA, ISBN 978-989-758-611-8; ISSN 2184-2825, pages 273-283. DOI: 10.5220/0011524700003332\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./jupyter_imgs/local_search_architecture.png', width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index for target features\n",
    "'5_o_Clock_Shadow', 0\n",
    "'Arched_Eyebrows', 1\n",
    "'Attractive', 2\n",
    "'Bags_Under_Eyes', 3 \n",
    "'Bald', 4\n",
    "'Bangs', 5\n",
    "'Big_Lips', 6 \n",
    "'Big_Nose', 7\n",
    "'Black_Hair', 8 \n",
    "'Blond_Hair', 9\n",
    "'Blurry', 10\n",
    "'Brown_Hair', 11 \n",
    "'Bushy_Eyebrows', 12 \n",
    "'Chubby', 13\n",
    "'Double_Chin', 14 \n",
    "'Eyeglasses', 15\n",
    "'Goatee', 16\n",
    "'Gray_Hair', 17 \n",
    "'Heavy_Makeup', 18 \n",
    "'High_Cheekbones', 19 \n",
    "'Male', 20\n",
    "'Mouth_Slightly_Open', 21 \n",
    "'Mustache', 22\n",
    "'Narrow_Eyes', 23 \n",
    "'No_Beard', 24\n",
    "'Oval_Face', 25\n",
    "'Pale_Skin', 26\n",
    "'Pointy_Nose', 27\n",
    "'Receding_Hairline', 28 \n",
    "'Rosy_Cheeks', 29\n",
    "'Sideburns', 30\n",
    "'Smiling',31\n",
    "'Straight_Hair', 32 \n",
    "'Wavy_Hair', 33\n",
    "'Wearing_Earrings', 34 \n",
    "'Wearing_Hat', 35\n",
    "'Wearing_Lipstick', 36 \n",
    "'Wearing_Necklace', 37\n",
    "'Wearing_Necktie', 38\n",
    "'Young' 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylegan2_path = \"./stylegan2-ada-pytorch\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(stylegan2_path)\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import click\n",
    "import dnnlib\n",
    "import legacy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = \"cuda:0\"\n",
    "size = 1024\n",
    "truncation_psi = 0.5\n",
    "n_iters = 65001\n",
    "batch_size = 1\n",
    "d = torch.zeros([1, 512]).to(device)\n",
    "norm_length = 1.0\n",
    "target_feature_index = 31\n",
    "learning_rate = 0.001\n",
    "\n",
    "noise_mode = 'const'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_folder = stylegan2_path + f'/training_runs/stylegan2/our_approach_feature_{target_feature_index}_maxLenght_{norm_length}_lr_{learning_rate}_batch_size{batch_size}'\n",
    "if not os.path.exists(logging_folder):\n",
    "    os.makedirs(logging_folder)\n",
    "\n",
    "if not os.path.exists(logging_folder + '/saved_latent_vecs'):\n",
    "    os.makedirs(logging_folder + '/saved_latent_vecs')\n",
    "\n",
    "with open(logging_folder + \"/training_log.txt\", \"a\") as myfile:\n",
    "            myfile.write(f'./training_runs/stylegan2/our_approach_feature_{target_feature_index}_maxLenght_{norm_length}_lr_{learning_rate}_batch_size{batch_size}' + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Normalization, self).__init__()\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "        self.mean = mean.clone().detach().view(-1, 1, 1)\n",
    "        self.std = std.clone().detach().view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return (img - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_pkl = './pretrained_models/ffhq.pkl'\n",
    "\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
    "\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    D = legacy.load_network_pkl(f)['D'].to(device)\n",
    "    \n",
    "label = torch.zeros([1, G.c_dim], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = torch.jit.load('./pretrained_models/resnet50.pth').eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./jupyter_imgs/local_search_pseudocode.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "for random_seed in range(n_iters):\n",
    "    with torch.no_grad():\n",
    "        z = torch.from_numpy(np.random.RandomState(random_seed).randn(batch_size, 512)).to(device)\n",
    "        w = G.mapping(z, label, truncation_psi=truncation_psi)\n",
    "        \n",
    "        epsilon = np.random.choice([-1,1])\n",
    "        img_d = G.synthesis(w+(d*epsilon), noise_mode=noise_mode)\n",
    "        img_d = F.interpolate(img_d, size=256)\n",
    "        alpha_d = regressor(img_d)[:, target_feature_index]\n",
    "        \n",
    "        d_new = d + learning_rate*torch.Tensor(np.random.RandomState(random_seed+n_iters).randn(1, 512)).to(device)\n",
    "        if torch.norm(d_new).item() > norm_length:\n",
    "            d_new = norm_length*d_new/torch.norm(d_new)\n",
    "        \n",
    "        img_d_new = G.synthesis(w+(d_new*epsilon), noise_mode=noise_mode)\n",
    "        img_d_new = F.interpolate(img_d_new, size=256)\n",
    "        alpha_d_new = regressor(img_d_new)[:, target_feature_index]\n",
    "        \n",
    "        print('pred_old:', alpha_d.mean().item(), 'pred_new:', alpha_d_new.mean().item())\n",
    "        with open(logging_folder + \"/training_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('pred_old: ' + str(alpha_d.mean().item()) + 'pred_new: ' + str(alpha_d_new.mean().item()) + '\\n')\n",
    "        \n",
    "        if random_seed%100 == 0:\n",
    "            torch.save(d, logging_folder+'/saved_latent_vecs/latent_vec_' + str(random_seed) + '.pt')\n",
    "        \n",
    "        if epsilon * alpha_d.mean().item() < epsilon*alpha_d_new.mean().item():\n",
    "            d = d_new\n",
    "            \n",
    "time2 = time.time()\n",
    "print('training-time: ', time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stylegan3",
   "language": "python",
   "name": "stylegan3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
